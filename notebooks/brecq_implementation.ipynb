{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0InvCnfP2Ink"
      },
      "outputs": [],
      "source": [
        "import torchvision.models as models\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_bits = 4"
      ],
      "metadata": {
        "id": "cIkHamXPjXr1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bn_folding(conv, bn):\n",
        "    # bn params\n",
        "    mu = bn.running_mean\n",
        "    var = bn.running_var\n",
        "    gamma = bn.weight\n",
        "    beta = bn.bias\n",
        "    eps = bn.eps\n",
        "\n",
        "    # conv params\n",
        "    w = conv.weight\n",
        "    b = conv.bias if conv.bias is not None else torch.zeros_like(mu)\n",
        "\n",
        "    denominator = torch.sqrt(var + eps)\n",
        "\n",
        "    w_new = w * (gamma / denominator).view(-1, 1, 1, 1)\n",
        "    b_new = (b - mu) * (gamma / denominator) + beta\n",
        "\n",
        "    conv.weight.data.copy_(w_new)\n",
        "\n",
        "    if conv.bias is not None:\n",
        "        conv.bias.data.copy_(b_new)\n",
        "    else:\n",
        "        conv.bias = nn.Parameter(b_new)\n",
        "\n",
        "    return nn.Identity()"
      ],
      "metadata": {
        "id": "VlW53WkZ3sxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fuse_resnet_module(model):\n",
        "    model.eval()\n",
        "\n",
        "    if hasattr(model, 'bn1') and not isinstance(model.bn1, nn.Identity):\n",
        "        model.bn1 = bn_folding(model.conv1, model.bn1)\n",
        "\n",
        "\n",
        "    for layer_name in ['layer1', 'layer2', 'layer3']:\n",
        "        layer = getattr(model, layer_name)\n",
        "        for i, block in enumerate(layer):\n",
        "            print(f'Fusing {layer_name}_{i}')\n",
        "\n",
        "            block.bn1 = bn_folding(block.conv1, block.bn1)\n",
        "            block.bn2 = bn_folding(block.conv2, block.bn2)\n",
        "\n",
        "            if block.downsample is not None:\n",
        "                ## 0이 conv 1이 bn\n",
        "                block.downsample[1] = bn_folding(block.downsample[0], block.downsample[1])\n",
        "\n",
        "    print(\" Folding completed\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "qZQ6Um644KLv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def round_ste(x):\n",
        "    return (x.round() - x).detach() + x\n",
        "\n",
        "class UniformQuantizer(nn.Module):\n",
        "    def __init__(self, n_bits=4, symmetric=True, channel_wise=False, is_weight=False):\n",
        "        super().__init__()\n",
        "\n",
        "        self.n_bits = n_bits\n",
        "        self.symmetric = symmetric\n",
        "        self.channel_wise = channel_wise\n",
        "        self.is_weight = is_weight # weight or activaition\n",
        "\n",
        "        # register_buffer를 통해 초기화\n",
        "        self.register_buffer('max_q', torch.tensor(2 ** (n_bits - 1) - 1))\n",
        "        self.register_buffer('min_q', torch.tensor(-2 ** (n_bits - 1)))\n",
        "        self.register_buffer('delta', None)\n",
        "        self.register_buffer('zero_point', None)\n",
        "\n",
        "    def init_quantization_params(self, x):\n",
        "\n",
        "        x_clone = x.clone().detach()\n",
        "\n",
        "        # channel_wise는 언제 사용할까 -> weight를 양자화 할 때, weight는 채널 마다 제각각이기 때문에\n",
        "        if self.channel_wise:\n",
        "            max_w = x_clone.abs().view(x_clone.shape[0], -1).max(1)[0]\n",
        "        else:\n",
        "            max_w = torch.max(torch.abs(x_clone))\n",
        "\n",
        "        if self.symmetric:\n",
        "            self.delta = (max_w / self.max_q).to(x.device)\n",
        "\n",
        "            if self.channel_wise:\n",
        "                self.delta = self.delta.view(-1, 1, 1, 1)\n",
        "                self.zero_point = torch.zeros_like(self.delta)\n",
        "            else:\n",
        "                self.zero_point = torch.tensor(0.0).to(x.device)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "\n",
        "        if self.delta is None:\n",
        "            self.init_quantization_params(x)\n",
        "\n",
        "        x_int = round_ste(x / self.delta) + self.zero_point\n",
        "        x_quant = torch.clamp(x_int, self.min_q, self.max_q)\n",
        "\n",
        "        return self.delta * (x_quant - self.zero_point)\n"
      ],
      "metadata": {
        "id": "kjcKB5YF4sgq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AdaRoundQuantizer(nn.Module):\n",
        "    def __init__(self, uq :UniformQuantizer, x):\n",
        "        super().__init__()\n",
        "\n",
        "        self.uq = uq\n",
        "        self.alpha = None # AdaRound parameter (v)\n",
        "        self.soft_targets = True # adaround 여부\n",
        "\n",
        "        # 고정 상수들을 buffer로 등록\n",
        "        self.register_buffer('gamma', torch.tensor(-0.1))\n",
        "        self.register_buffer('zeta', torch.tensor(1.1))\n",
        "\n",
        "        self.init_alpha(x.clone())\n",
        "\n",
        "    def init_alpha(self, x):\n",
        "        w_floor = torch.floor(x / self.uq.delta)\n",
        "\n",
        "        rest = (x / self.uq.delta) - w_floor\n",
        "        rest = torch.clamp(rest, 0.01, 0.99)\n",
        "\n",
        "        sig_inv = (rest - self.gamma) / (self.zeta - self.gamma)\n",
        "        sig_inv = torch.clamp(sig_inv, 0.01, 0.99)\n",
        "\n",
        "        alpha = torch.log(sig_inv / (1 - sig_inv))\n",
        "        self.alpha = nn.Parameter(alpha)\n",
        "\n",
        "    def rectified_sigmoid(self):\n",
        "        # Equation 23\n",
        "        x = torch.clamp(torch.sigmoid(self.alpha) * (self.zeta - self.gamma) + self.gamma, 0, 1)\n",
        "\n",
        "        return x\n",
        "\n",
        "    def forward(self, x):\n",
        "        w_floor = torch.floor(x / self.uq.delta)\n",
        "\n",
        "        # 모드에 따라 0~1 사이의 값(soft) 또는 0/1 값(hard)을 결정\n",
        "        if self.soft_targets:\n",
        "            rounding_val = self.rectified_sigmoid()\n",
        "        else:\n",
        "            rounding_val = (self.alpha >= 0.5).float()\n",
        "\n",
        "        w_int = w_floor + rounding_val\n",
        "        w_quant = self.uq.delta * torch.clamp(w_int - self.uq.zero_point, self.uq.min_q, self.uq.max_q)\n",
        "\n",
        "        return w_quant"
      ],
      "metadata": {
        "id": "o4PMK_y-4wat"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class QuantModule(nn.Module):\n",
        "    def __init__(self, org_module: nn.Conv2d, weight_quantizer):\n",
        "        super().__init__()\n",
        "        self.org_module = org_module\n",
        "        self.weight_quantizer = weight_quantizer # 아까 만든 AdaRoundQuantizer\n",
        "        self.use_quantization = True # 스위치\n",
        "        self.conv_type = dict(bias = self.org_module.bias,\n",
        "                              stride = self.org_module.stride, padding = self.org_module.padding,\n",
        "                                dilation=self.org_module.dilation, groups=self.org_module.groups)\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_quantization:\n",
        "            # 가중치 가져오기\n",
        "            w = self.org_module.weight\n",
        "\n",
        "            # 가중치 양자화 (여기서 AdaRound가 작동)\n",
        "            w_q = self.weight_quantizer(w)\n",
        "\n",
        "            # 양자화된 가중치로 Conv 연산\n",
        "            out = F.conv2d(x, w_q, **self.conv_type)\n",
        "            return out\n",
        "        else:\n",
        "            return self.org_module(x)"
      ],
      "metadata": {
        "id": "TKWGkGLU403G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_to_quant_module(model, skip_first=True):\n",
        "    \"\"\"\n",
        "    모델을 재귀적으로 탐색하며 nn.Conv2d를 QuantModule로 교체\n",
        "    \"\"\"\n",
        "    for name, module in model.named_children():\n",
        "\n",
        "        if skip_first and name in [\"conv1\", \"bn1\"]:\n",
        "            continue\n",
        "\n",
        "        if isinstance(module, nn.Conv2d):\n",
        "\n",
        "            # UniformQuantizer 먼저 만들고 -> AdaRoundQuantizer로 감싸기\n",
        "            uq = UniformQuantizer(n_bits=n_bits, symmetric=True, channel_wise=True, is_weight=True)\n",
        "\n",
        "            # 초기화를 위해 가중치 한번 넣어줌 (init_quantization_params)\n",
        "            uq.init_quantization_params(module.weight)\n",
        "\n",
        "            # AdaRound Quantizer 생성\n",
        "            ada_quantizer = AdaRoundQuantizer(uq, module.weight)\n",
        "\n",
        "            # Wrapper로 교체\n",
        "            quant_module = QuantModule(module, ada_quantizer)\n",
        "            setattr(model, name, quant_module)\n",
        "\n",
        "        elif len(list(module.children())) > 0:\n",
        "            # 자식 모듈이 더 있으면 재귀 호출\n",
        "            replace_to_quant_module(module, skip_first=False)"
      ],
      "metadata": {
        "id": "soSxjF0h5Acn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EfficientDataSaver:\n",
        "    def __init__(self, total_samples, in_c, in_h, in_w, out_c, out_h, out_w):\n",
        "        self.inputs = torch.zeros((total_samples, in_c, in_h, in_w), dtype=torch.float32)\n",
        "        self.outputs = torch.zeros((total_samples, out_c, out_h, out_w), dtype=torch.float32)\n",
        "        self.grads = torch.zeros((total_samples, out_c, out_h, out_w), dtype=torch.float32)\n",
        "        self.idx = 0\n",
        "        self.backward_idx = 0\n",
        "\n",
        "    def hook_fn(self, module, input, output):\n",
        "        batch_size = input[0].shape[0]\n",
        "        curr_idx = self.idx\n",
        "\n",
        "        if curr_idx + batch_size <= self.inputs.shape[0]:\n",
        "\n",
        "            self.inputs[curr_idx : curr_idx + batch_size] = input[0].detach().cpu()\n",
        "            self.outputs[curr_idx : curr_idx + batch_size] = output.detach().cpu()\n",
        "\n",
        "            self.idx += batch_size\n",
        "\n",
        "    def hook_backward(self, module, grad_input, grad_output):\n",
        "        if grad_output[0] is None:\n",
        "            return None\n",
        "\n",
        "        batch_size = grad_output[0].shape[0]\n",
        "        curr_idx = self.backward_idx\n",
        "\n",
        "        if curr_idx + batch_size <= self.grads.shape[0]:\n",
        "\n",
        "            self.grads[curr_idx : curr_idx + batch_size] = grad_output[0].detach().cpu()\n",
        "            self.backward_idx += batch_size\n",
        "\n",
        "        return None"
      ],
      "metadata": {
        "id": "g-zjkoOu5YDv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim import Adam\n",
        "import numpy as np\n",
        "\n",
        "def block_reconstruction(block, cali_inputs, cali_outputs, cali_grads, quantizers, batch_size=64, iters=1000):\n",
        "\n",
        "    # 학습 파라미터 추출 및 adaround 설정\n",
        "    params = []\n",
        "    for q in quantizers:\n",
        "        params.append(q.alpha)\n",
        "        q.soft_targets = True\n",
        "\n",
        "    optimizer = Adam(params, lr=1e-3)\n",
        "\n",
        "    dataset = TensorDataset(cali_inputs.cpu(), cali_outputs.cpu(), cali_grads.cpu())\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    beta_scheduler = np.linspace(20, 2, iters)\n",
        "\n",
        "    for i in range(iters):\n",
        "        beta = beta_scheduler[i]\n",
        "\n",
        "        for x_batch, y_batch, g_batch in loader:\n",
        "            # 여기서 데이터를 GPU로 이동하여 메모리 절약\n",
        "            cur_input = x_batch.to(device) # Input\n",
        "            cur_target = y_batch.to(device) # Output (Target)\n",
        "            cur_grad = g_batch.to(device) # Fisher (Weight)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward (Soft Quantization)\n",
        "            out_quant = block(cur_input)\n",
        "\n",
        "            # Fisher Loss 계산\n",
        "            # sum( (output_diff * grad)^2 )\n",
        "            delta = out_quant - cur_target\n",
        "\n",
        "            loss_rec = (delta * cur_grad).pow(2).sum()\n",
        "\n",
        "            # 데이터 개수로 정규화\n",
        "            loss_rec = loss_rec / batch_size\n",
        "\n",
        "            # Regularization Loss\n",
        "            loss_reg = 0\n",
        "\n",
        "            for q in quantizers:\n",
        "                soft_val = q.rectified_sigmoid()\n",
        "                reg_term = 1.0 - (2 * soft_val - 1).abs().pow(beta)\n",
        "                loss_reg += reg_term.sum()\n",
        "\n",
        "            # Total Loss\n",
        "            total_loss = loss_rec + 1e-4 * loss_reg\n",
        "\n",
        "            total_loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "        if i % 200 == 0:\n",
        "            print(f\"Iter {i}: Total {total_loss.item():.4f} (Rec {loss_rec.item():.10f})\")\n",
        "\n",
        "\n",
        "    # 학습 종료 후 Hard Mode로 전환\n",
        "    for q in quantizers:\n",
        "        q.soft_targets = False"
      ],
      "metadata": {
        "id": "iBkBWD7L5lHJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_quantizers_from_block(block):\n",
        "    \"\"\"블록 내부의 모든 QuantModule에서 weight_quantizer를 추출\"\"\"\n",
        "    quantizers = []\n",
        "    for name, module in block.named_modules():\n",
        "        if isinstance(module, QuantModule):\n",
        "            quantizers.append(module.weight_quantizer)\n",
        "    return quantizers\n",
        "\n",
        "\n",
        "def set_quant_state(module, use_quant=True):\n",
        "    \"\"\"\n",
        "    블록 내의 모든 QuantModule의 양자화 스위치를 켜거나 끕니다.\n",
        "    \"\"\"\n",
        "    for m in module.modules():\n",
        "        if isinstance(m, QuantModule):\n",
        "            m.use_quantization = use_quant\n",
        "\n",
        "\n",
        "def run_brecq(model, dataloader, target_block, num_samples=128):\n",
        "    model.eval().to(device)\n",
        "\n",
        "    sample_img, _ = next(iter(dataloader))\n",
        "    sample_img = sample_img[:1].to(device) # 1개만 사용\n",
        "\n",
        "    block_shape = {}\n",
        "    def get_shape_hook(module, input, output):\n",
        "        # input[0]은 입력 텐서, output은 출력 텐서\n",
        "        block_shape['in'] = input[0].shape[1:]  # (C, H, W)\n",
        "        block_shape['out'] = output.shape[1:]    # (C, H, W)\n",
        "\n",
        "    handle = target_block.register_forward_hook(get_shape_hook)\n",
        "    with torch.no_grad():\n",
        "        model(sample_img)\n",
        "    handle.remove()\n",
        "\n",
        "    in_c, in_h, in_w = block_shape['in']\n",
        "    out_c, out_h, out_w = block_shape['out']\n",
        "\n",
        "    # 입력과 출력의 크기가 다를 수 있으므로(stride 등) 각각 할당합니다.\n",
        "    saver = EfficientDataSaver(num_samples, in_c, in_h, in_w, out_c, out_h, out_w)\n",
        "\n",
        "    set_quant_state(target_block, use_quant=False)\n",
        "\n",
        "    # Hook 등록\n",
        "    # forward: 입력(input)과 정답(output) 수집\n",
        "    h1 = target_block.register_forward_hook(saver.hook_fn)\n",
        "    # backward: 중요도(gradient) 수집\n",
        "    h2 = target_block.register_full_backward_hook(saver.hook_backward)\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "    print(\"Step 1: Collecting Data & Gradients...\")\n",
        "    current_samples = 0\n",
        "    for imgs, labels in dataloader:\n",
        "        if current_samples >= num_samples: break\n",
        "        imgs, labels = imgs.to(device), labels.to(device)\n",
        "        imgs.requires_grad_(True)\n",
        "\n",
        "        model.zero_grad()\n",
        "        out = model(imgs)\n",
        "        loss = criterion(out, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        current_samples += imgs.shape[0]\n",
        "\n",
        "\n",
        "    # Hook 제거\n",
        "    h1.remove()\n",
        "    h2.remove()\n",
        "\n",
        "    set_quant_state(target_block, use_quant=True)\n",
        "\n",
        "    # Quantizer 추출\n",
        "    quantizers = get_quantizers_from_block(target_block)\n",
        "\n",
        "    print(\"Step 2: Optimizing Block...\")\n",
        "    block_reconstruction(\n",
        "        target_block,\n",
        "        saver.inputs, saver.outputs, saver.grads,\n",
        "        quantizers,\n",
        "        iters=1000\n",
        "    )\n",
        "\n",
        "    print(\"Done!\")"
      ],
      "metadata": {
        "id": "oW1Rf-ZA5tZ8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_model(model, test_loader, device):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in test_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.shape[0]\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    return accuracy"
      ],
      "metadata": {
        "id": "iGq0ZZH-5971"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def optimize_full_model(model, calib_loader):\n",
        "    target_blocks = []\n",
        "\n",
        "    if isinstance(model.conv1, QuantModule):\n",
        "        target_blocks.append(model.conv1)\n",
        "\n",
        "    # 각 Layer 내부의 BasicBlock들 추출\n",
        "    for layer_name in ['layer1', 'layer2', 'layer3']:\n",
        "        layer = getattr(model, layer_name)\n",
        "        for block in layer:\n",
        "            target_blocks.append(block)\n",
        "\n",
        "    print(f\"Total blocks to optimize: {len(target_blocks)}\")\n",
        "\n",
        "    # 블록별 순차 최적화 진행\n",
        "    for i, block in enumerate(target_blocks):\n",
        "        print(f\"\\n>>> [Step {i+1}/{len(target_blocks)}] Optimizing Block: {block.__class__.__name__}\")\n",
        "        run_brecq(model, calib_loader, block)"
      ],
      "metadata": {
        "id": "yodcH0Zq6JI5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
        "    ])\n",
        "\n",
        "# 1. 데이터셋 준비 (Test용과 Calibration용 분리)\n",
        "calib_dataset = torchvision.datasets.CIFAR100(root='./data', train=True, download=True, transform=transform)\n",
        "calib_loader = torch.utils.data.DataLoader(torch.utils.data.Subset(calib_dataset, range(1024)), batch_size=32, shuffle=False)\n",
        "\n",
        "test_dataset = torchvision.datasets.CIFAR100(root='./data', train=False, download=True, transform=transform)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False)\n",
        "\n",
        "# 2. Baseline(FP32) 성능 측정\n",
        "base_model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_resnet44\", pretrained=True).to(device)\n",
        "base_model.eval()\n",
        "print(\"Calculating Baseline Accuracy...\")\n",
        "fp32_acc = validate_model(base_model, test_loader, device)\n",
        "print(f\"Baseline (FP32) Accuracy: {fp32_acc:.2f}%\")\n",
        "\n",
        "# 3. 양자화 모델 준비 (BN Folding & Module Replacement)\n",
        "# base_model을 그대로 쓰면 덮어씌워지므로\n",
        "def disable_inplace_relu(model):\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, nn.ReLU):\n",
        "            m.inplace = False\n",
        "\n",
        "# 실행 코드에 추가\n",
        "q_model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar100_resnet44\", pretrained=True).to(device)\n",
        "disable_inplace_relu(q_model) # 최적화 전 반드시 실행\n",
        "q_model = fuse_resnet_module(q_model)\n",
        "replace_to_quant_module(q_model) #\n",
        "q_model.to(device)\n",
        "\n",
        "# 모델의 첫 번째 파라미터가 어디에 있는지 확인\n",
        "print(f\"Model device: {next(q_model.parameters()).device}\")\n",
        "\n",
        "# 4. 전체 모델 BRECQ 최적화 실행\n",
        "optimize_full_model(q_model, calib_loader)\n",
        "\n",
        "# 5. 양자화 모델 성능 측정\n",
        "print(\"\\nCalculating Quantized Model Accuracy...\")\n",
        "q_acc = validate_model(q_model, test_loader, device)\n",
        "\n",
        "# 6. 최종 결과 비교\n",
        "print(\"\\n\" + \"=\"*30)\n",
        "print(f\"FP32 Accuracy: {fp32_acc:.2f}%\")\n",
        "print(f\"W4A32 BRECQ Accuracy: {q_acc:.2f}%\")\n",
        "print(f\"Accuracy Drop: {fp32_acc - q_acc:.2f}%\")\n",
        "print(\"=\"*30)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTpOy7Wg6N2t",
        "outputId": "8f4a1f31-7cf1-492a-e928-9306d49caac4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 169M/169M [00:09<00:00, 17.8MB/s]\n",
            "/usr/local/lib/python3.12/dist-packages/torch/hub.py:335: UserWarning: You are about to download and run code from an untrusted repository. In a future release, this won't be allowed. To add the repository to your trusted list, change the command to {calling_fn}(..., trust_repo=False) and a command prompt will appear asking for an explicit confirmation of trust, or load(..., trust_repo=True), which will assume that the prompt is to be answered with 'yes'. You can also use load(..., trust_repo='check') which will only prompt for confirmation if the repo is not already trusted. This will eventually be the default behaviour\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/zipball/master\" to /root/.cache/torch/hub/master.zip\n",
            "Downloading: \"https://github.com/chenyaofo/pytorch-cifar-models/releases/download/resnet/cifar100_resnet44-ffe32858.pt\" to /root/.cache/torch/hub/checkpoints/cifar100_resnet44-ffe32858.pt\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 2.64M/2.64M [00:00<00:00, 75.0MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculating Baseline Accuracy...\n",
            "Baseline (FP32) Accuracy: 67.79%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fusing layer1_0\n",
            "Fusing layer1_1\n",
            "Fusing layer1_2\n",
            "Fusing layer1_3\n",
            "Fusing layer1_4\n",
            "Fusing layer1_5\n",
            "Fusing layer1_6\n",
            "Fusing layer2_0\n",
            "Fusing layer2_1\n",
            "Fusing layer2_2\n",
            "Fusing layer2_3\n",
            "Fusing layer2_4\n",
            "Fusing layer2_5\n",
            "Fusing layer2_6\n",
            "Fusing layer3_0\n",
            "Fusing layer3_1\n",
            "Fusing layer3_2\n",
            "Fusing layer3_3\n",
            "Fusing layer3_4\n",
            "Fusing layer3_5\n",
            "Fusing layer3_6\n",
            " Folding completed\n",
            "Model device: cuda:0\n",
            "Total blocks to optimize: 21\n",
            "\n",
            ">>> [Step 1/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 0.4385 (Rec 0.0000000004)\n",
            "Iter 200: Total 0.3302 (Rec 0.0000001768)\n",
            "Iter 400: Total 0.2061 (Rec 0.0000004140)\n",
            "Iter 600: Total 0.1614 (Rec 0.0000006563)\n",
            "Iter 800: Total 0.1050 (Rec 0.0000011631)\n",
            "Done!\n",
            "\n",
            ">>> [Step 2/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 0.4384 (Rec 0.0000000001)\n",
            "Iter 200: Total 0.3359 (Rec 0.0000001498)\n",
            "Iter 400: Total 0.2089 (Rec 0.0000001890)\n",
            "Iter 600: Total 0.1608 (Rec 0.0000005140)\n",
            "Iter 800: Total 0.1044 (Rec 0.0000006315)\n",
            "Done!\n",
            "\n",
            ">>> [Step 3/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 0.4382 (Rec 0.0000000000)\n",
            "Iter 200: Total 0.3316 (Rec 0.0000000568)\n",
            "Iter 400: Total 0.2022 (Rec 0.0000001550)\n",
            "Iter 600: Total 0.1555 (Rec 0.0000001978)\n",
            "Iter 800: Total 0.1007 (Rec 0.0000003821)\n",
            "Done!\n",
            "\n",
            ">>> [Step 4/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 0.4387 (Rec 0.0000000000)\n",
            "Iter 200: Total 0.3368 (Rec 0.0000001043)\n",
            "Iter 400: Total 0.2038 (Rec 0.0000002171)\n",
            "Iter 600: Total 0.1571 (Rec 0.0000002321)\n",
            "Iter 800: Total 0.1010 (Rec 0.0000003227)\n",
            "Done!\n",
            "\n",
            ">>> [Step 5/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 0.4376 (Rec 0.0000000000)\n",
            "Iter 200: Total 0.3330 (Rec 0.0000000608)\n",
            "Iter 400: Total 0.1985 (Rec 0.0000001534)\n",
            "Iter 600: Total 0.1522 (Rec 0.0000002434)\n",
            "Iter 800: Total 0.0967 (Rec 0.0000002499)\n",
            "Done!\n",
            "\n",
            ">>> [Step 6/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 0.4364 (Rec 0.0000000000)\n",
            "Iter 200: Total 0.3321 (Rec 0.0000000686)\n",
            "Iter 400: Total 0.2004 (Rec 0.0000002085)\n",
            "Iter 600: Total 0.1583 (Rec 0.0000001178)\n",
            "Iter 800: Total 0.1029 (Rec 0.0000003111)\n",
            "Done!\n",
            "\n",
            ">>> [Step 7/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 0.4373 (Rec 0.0000000001)\n",
            "Iter 200: Total 0.3307 (Rec 0.0000000695)\n",
            "Iter 400: Total 0.1987 (Rec 0.0000001708)\n",
            "Iter 600: Total 0.1526 (Rec 0.0000002044)\n",
            "Iter 800: Total 0.0968 (Rec 0.0000003054)\n",
            "Done!\n",
            "\n",
            ">>> [Step 8/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 1.3654 (Rec 0.0000000010)\n",
            "Iter 200: Total 1.0410 (Rec 0.0000004053)\n",
            "Iter 400: Total 0.6404 (Rec 0.0000008646)\n",
            "Iter 600: Total 0.5026 (Rec 0.0000018944)\n",
            "Iter 800: Total 0.3249 (Rec 0.0000028098)\n",
            "Done!\n",
            "\n",
            ">>> [Step 9/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 1.7588 (Rec 0.0000000000)\n",
            "Iter 200: Total 1.3468 (Rec 0.0000001388)\n",
            "Iter 400: Total 0.8247 (Rec 0.0000002727)\n",
            "Iter 600: Total 0.6493 (Rec 0.0000005243)\n",
            "Iter 800: Total 0.4141 (Rec 0.0000008934)\n",
            "Done!\n",
            "\n",
            ">>> [Step 10/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 1.7603 (Rec 0.0000000001)\n",
            "Iter 200: Total 1.3446 (Rec 0.0000001121)\n",
            "Iter 400: Total 0.8280 (Rec 0.0000002741)\n",
            "Iter 600: Total 0.6435 (Rec 0.0000005111)\n",
            "Iter 800: Total 0.4177 (Rec 0.0000006220)\n",
            "Done!\n",
            "\n",
            ">>> [Step 11/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 1.7581 (Rec 0.0000000000)\n",
            "Iter 200: Total 1.3425 (Rec 0.0000001361)\n",
            "Iter 400: Total 0.8221 (Rec 0.0000002421)\n",
            "Iter 600: Total 0.6439 (Rec 0.0000002381)\n",
            "Iter 800: Total 0.4143 (Rec 0.0000004940)\n",
            "Done!\n",
            "\n",
            ">>> [Step 12/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 1.7542 (Rec 0.0000000000)\n",
            "Iter 200: Total 1.3349 (Rec 0.0000001449)\n",
            "Iter 400: Total 0.8179 (Rec 0.0000003091)\n",
            "Iter 600: Total 0.6334 (Rec 0.0000005267)\n",
            "Iter 800: Total 0.4090 (Rec 0.0000005774)\n",
            "Done!\n",
            "\n",
            ">>> [Step 13/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 1.7576 (Rec 0.0000000000)\n",
            "Iter 200: Total 1.3451 (Rec 0.0000000584)\n",
            "Iter 400: Total 0.8272 (Rec 0.0000001964)\n",
            "Iter 600: Total 0.6448 (Rec 0.0000002991)\n",
            "Iter 800: Total 0.4166 (Rec 0.0000003817)\n",
            "Done!\n",
            "\n",
            ">>> [Step 14/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 1.7551 (Rec 0.0000000000)\n",
            "Iter 200: Total 1.3437 (Rec 0.0000001134)\n",
            "Iter 400: Total 0.8207 (Rec 0.0000002200)\n",
            "Iter 600: Total 0.6395 (Rec 0.0000004200)\n",
            "Iter 800: Total 0.4142 (Rec 0.0000004967)\n",
            "Done!\n",
            "\n",
            ">>> [Step 15/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 5.4616 (Rec 0.0000000004)\n",
            "Iter 200: Total 4.1593 (Rec 0.0000007939)\n",
            "Iter 400: Total 2.5552 (Rec 0.0000018070)\n",
            "Iter 600: Total 1.9988 (Rec 0.0000034929)\n",
            "Iter 800: Total 1.2939 (Rec 0.0000041176)\n",
            "Done!\n",
            "\n",
            ">>> [Step 16/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 7.0273 (Rec 0.0000000001)\n",
            "Iter 200: Total 5.3499 (Rec 0.0000004495)\n",
            "Iter 400: Total 3.2877 (Rec 0.0000009116)\n",
            "Iter 600: Total 2.5719 (Rec 0.0000013711)\n",
            "Iter 800: Total 1.6651 (Rec 0.0000020046)\n",
            "Done!\n",
            "\n",
            ">>> [Step 17/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 7.0319 (Rec 0.0000000001)\n",
            "Iter 200: Total 5.3779 (Rec 0.0000005170)\n",
            "Iter 400: Total 3.2938 (Rec 0.0000006347)\n",
            "Iter 600: Total 2.5638 (Rec 0.0000012550)\n",
            "Iter 800: Total 1.6505 (Rec 0.0000019399)\n",
            "Done!\n",
            "\n",
            ">>> [Step 18/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 7.0419 (Rec 0.0000000000)\n",
            "Iter 200: Total 5.3783 (Rec 0.0000001830)\n",
            "Iter 400: Total 3.2919 (Rec 0.0000006537)\n",
            "Iter 600: Total 2.5713 (Rec 0.0000015316)\n",
            "Iter 800: Total 1.6606 (Rec 0.0000014046)\n",
            "Done!\n",
            "\n",
            ">>> [Step 19/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 7.0390 (Rec 0.0000000000)\n",
            "Iter 200: Total 5.3649 (Rec 0.0000001748)\n",
            "Iter 400: Total 3.2995 (Rec 0.0000003329)\n",
            "Iter 600: Total 2.5930 (Rec 0.0000004782)\n",
            "Iter 800: Total 1.6652 (Rec 0.0000009408)\n",
            "Done!\n",
            "\n",
            ">>> [Step 20/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 7.0415 (Rec 0.0000000000)\n",
            "Iter 200: Total 5.3713 (Rec 0.0000000819)\n",
            "Iter 400: Total 3.2938 (Rec 0.0000001483)\n",
            "Iter 600: Total 2.5733 (Rec 0.0000002077)\n",
            "Iter 800: Total 1.6506 (Rec 0.0000003947)\n",
            "Done!\n",
            "\n",
            ">>> [Step 21/21] Optimizing Block: BasicBlock\n",
            "Step 1: Collecting Data & Gradients...\n",
            "Step 2: Optimizing Block...\n",
            "Iter 0: Total 7.0343 (Rec 0.0000000000)\n",
            "Iter 200: Total 5.3653 (Rec 0.0000000159)\n",
            "Iter 400: Total 3.2920 (Rec 0.0000000394)\n",
            "Iter 600: Total 2.5803 (Rec 0.0000000531)\n",
            "Iter 800: Total 1.6641 (Rec 0.0000000962)\n",
            "Done!\n",
            "\n",
            "Calculating Quantized Model Accuracy...\n",
            "\n",
            "==============================\n",
            "FP32 Accuracy: 67.79%\n",
            "W4A32 BRECQ Accuracy: 65.39%\n",
            "Accuracy Drop: 2.40%\n",
            "==============================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "def pack_weights(w_int8):\n",
        "    tmp = 2**(n_bits-1)\n",
        "    group = 32 // n_bits\n",
        "    w_uint = (w_int8.t().contiguous() + tmp).to(torch.int32)\n",
        "\n",
        "    K, N = w_uint.shape\n",
        "    w_reshaped = w_uint.view(K, N // group, group)\n",
        "\n",
        "    w_packed = torch.zeros((K, N//group), dtype=torch.int32, device=w_int8.device)\n",
        "\n",
        "    for i in range(group):\n",
        "        curr = w_reshaped[:, :, i]\n",
        "        w_packed |= (curr << (i * n_bits))\n",
        "\n",
        "    return w_packed\n",
        "\n",
        "def quantization(w, quantizer):\n",
        "\n",
        "    w_floor = torch.floor(w / quantizer.uq.delta)\n",
        "    rounding = (quantizer.alpha >= 0).float()\n",
        "    w_int = w_floor + rounding\n",
        "    w_int = torch.clamp(w_int - quantizer.uq.zero_point, quantizer.uq.min_q, quantizer.uq.max_q)\n",
        "\n",
        "    return w_int\n",
        "\n",
        "def padding_params(w, scale, zp, bias, BN=128):\n",
        "    out_ch, in_ch = w.shape[0], w.shape[1]\n",
        "\n",
        "    pad_n = (BN - out_ch % BN) % BN\n",
        "\n",
        "    if pad_n > 0:\n",
        "        w = F.pad(w, (0, 0, 0, pad_n), value=0.0)\n",
        "        scale = F.pad(scale, (0, pad_n), value=1.0)\n",
        "        zp = F.pad(zp, (0, pad_n), value=0.0)\n",
        "        bias = F.pad(bias, (0, pad_n), value=0.0)\n",
        "\n",
        "    return w, scale, zp, bias\n",
        "\n",
        "\n",
        "\n",
        "def export_quantized_model(model, save_path=\"resnet44_w4a32.pt\"):\n",
        "    print(\"Exporting Quantized Model with Dual Padding (K & N)...\")\n",
        "    quantized_state_dict = {}\n",
        "\n",
        "    for name, module in model.named_modules():\n",
        "        if isinstance(module, QuantModule):\n",
        "            print(f\"Processing: {name}\")\n",
        "\n",
        "            # 1.\n",
        "            quantizer = module.weight_quantizer\n",
        "            w = module.org_module.weight # (Out, In, k, k)\n",
        "            delta = quantizer.uq.delta\n",
        "\n",
        "            # 2.\n",
        "            w_int = quantization(w, quantizer)\n",
        "            out_ch = w_int.shape[0]\n",
        "            w_flat = w_int.view(out_ch, -1) # [Out, K]\n",
        "\n",
        "            scale = delta.cpu().view(-1) # [Out, ]\n",
        "            zp = quantizer.uq.zero_point.cpu().view(-1) # [Out, ]\n",
        "\n",
        "            if module.org_module.bias is not None:\n",
        "                bias = module.org_module.bias.cpu()\n",
        "            else:\n",
        "                bias = torch.zeros_like(scale)\n",
        "\n",
        "            # 3.\n",
        "            w_padded, scale, zp, bias = padding_params(w_flat, scale, zp, bias)\n",
        "\n",
        "            w_packed = pack_weights(w_padded).contiguous() # [K, Out / (32 / n_bits)]\n",
        "            zp = zp + 2**(n_bits-1)\n",
        "\n",
        "            # 딕셔너리에 저장\n",
        "            quantized_state_dict[f\"{name}.w_packed\"] = w_packed.cpu() # [K, Out_padded / (32 / n_bits)]\n",
        "            quantized_state_dict[f\"{name}.scale\"] = scale # [Out_padded, ]\n",
        "            quantized_state_dict[f\"{name}.zero_point\"] = zp # [Out_padded, ]\n",
        "            quantized_state_dict[f\"{name}.bias\"] = bias # [Out_padded, ]\n",
        "\n",
        "    # 저장\n",
        "    torch.save(quantized_state_dict, save_path)\n",
        "    print(f\"Saved to {save_path}\")"
      ],
      "metadata": {
        "id": "kuWZrfzJTYgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n1JK9VDR-QG8",
        "outputId": "9345e85a-68cb-4d20-ac24-3d82137cca7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# 1. 저장할 경로와 파일명 지정\n",
        "# 예: 내 드라이브의 'Projects' 폴더 안에 'resnet_quantized.pt'로 저장하고 싶다면:\n",
        "save_dir = '/content/drive/MyDrive/Colab Notebooks/source'\n",
        "filename = 'resnet44_w4a32.pt'\n",
        "save_path = os.path.join(save_dir, filename)\n",
        "\n",
        "# (폴더가 없으면 에러가 나므로 미리 생성해주는 것이 안전합니다)\n",
        "os.makedirs(save_dir, exist_ok=True)"
      ],
      "metadata": {
        "id": "wfkmNXEn-Qz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "export_quantized_model(q_model, save_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5au3miXQ-Tyq",
        "outputId": "73e5d0bc-dea4-4e26-c4ad-8455272eaf14"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exporting Quantized Model with Dual Padding (K & N)...\n",
            "Processing: layer1.0.conv1\n",
            "Processing: layer1.0.conv2\n",
            "Processing: layer1.1.conv1\n",
            "Processing: layer1.1.conv2\n",
            "Processing: layer1.2.conv1\n",
            "Processing: layer1.2.conv2\n",
            "Processing: layer1.3.conv1\n",
            "Processing: layer1.3.conv2\n",
            "Processing: layer1.4.conv1\n",
            "Processing: layer1.4.conv2\n",
            "Processing: layer1.5.conv1\n",
            "Processing: layer1.5.conv2\n",
            "Processing: layer1.6.conv1\n",
            "Processing: layer1.6.conv2\n",
            "Processing: layer2.0.conv1\n",
            "Processing: layer2.0.conv2\n",
            "Processing: layer2.0.downsample.0\n",
            "Processing: layer2.1.conv1\n",
            "Processing: layer2.1.conv2\n",
            "Processing: layer2.2.conv1\n",
            "Processing: layer2.2.conv2\n",
            "Processing: layer2.3.conv1\n",
            "Processing: layer2.3.conv2\n",
            "Processing: layer2.4.conv1\n",
            "Processing: layer2.4.conv2\n",
            "Processing: layer2.5.conv1\n",
            "Processing: layer2.5.conv2\n",
            "Processing: layer2.6.conv1\n",
            "Processing: layer2.6.conv2\n",
            "Processing: layer3.0.conv1\n",
            "Processing: layer3.0.conv2\n",
            "Processing: layer3.0.downsample.0\n",
            "Processing: layer3.1.conv1\n",
            "Processing: layer3.1.conv2\n",
            "Processing: layer3.2.conv1\n",
            "Processing: layer3.2.conv2\n",
            "Processing: layer3.3.conv1\n",
            "Processing: layer3.3.conv2\n",
            "Processing: layer3.4.conv1\n",
            "Processing: layer3.4.conv2\n",
            "Processing: layer3.5.conv1\n",
            "Processing: layer3.5.conv2\n",
            "Processing: layer3.6.conv1\n",
            "Processing: layer3.6.conv2\n",
            "Saved to /content/drive/MyDrive/Colab Notebooks/source/resnet44_w4a32.pt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "55J8cdsooC5G"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}